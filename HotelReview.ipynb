{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Hotel Review\n",
    "\n",
    "We aim to perform sentiment analysis on customer reviews to understand their \n",
    "sentiments towards a product or service. This helps us to understand customer \n",
    "satisfaction and areas that need improvement.\n",
    " \n",
    "NLP Techniques: \n",
    "1. Text Preprocessing: Tokenization, stop word removal and lemmatization. \n",
    "2. Feature Extraction: Bag of Words, Term Frequency â€“ Inverse Document \n",
    "Frequency (TF-IDF) and word embeddings. \n",
    "3. Sentiment Classification: Random Forest (RF) Classifier, Logistic Regression, \n",
    "CNN "
   ],
   "id": "6e6cea933937d532"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Data Preparation\n",
    "\n",
    "The data provided is stored as csv, after some data preparation and cleaning text we decide to transform this into pickle format.\n",
    "Each customer review is a textual feedback and an overall rating.  \n",
    "The ratings can range from 1 to 10.  \n",
    "We will split them into two categories: bad reviews have ratings < 5 and good reviews have ratings >= 5.\n",
    "\n",
    "The textual is divide into two part (positive and negative). We group the together in order to start with only one raw text data.\n",
    "additionally if the user doesn't leave any negative or positive comment, this will appear as \"No Negative\" or \"No Positive\". those part have to be removed from the text."
   ],
   "id": "8bb61824f59232d6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T09:54:23.489574Z",
     "start_time": "2024-06-18T09:54:23.464495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#no more needed after data converting to pickle\n",
    "'''import pandas as pd\n",
    "\n",
    "#read data\n",
    "reviews_df = pd.read_csv('dataset/Hotel_Reviews.csv')\n",
    "\n",
    "#append the positive and negative reviews\n",
    "reviews_df['review'] = reviews_df['Negative_Review'] + reviews_df['Positive_Review']\n",
    "#create the label\n",
    "reviews_df['review_type'] = reviews_df['Reviewer_Score'].apply(lambda x: 'Bad_review' if x < 5 else 'Good_review')\n",
    "#sample data in order to speed up the computation\n",
    "reviews_df = reviews_df.sample(frac=0.1, replace=False, random_state=42)\n",
    "#clean data\n",
    "reviews_df['review'] = reviews_df['review'].apply(lambda x: x.replace('No Negative', '').replace('No Positive', '')) '''\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import pandas as pd\\n\\n#read data\\nreviews_df = pd.read_csv('dataset/Hotel_Reviews.csv')\\n\\n#append the positive and negative reviews\\nreviews_df['review'] = reviews_df['Negative_Review'] + reviews_df['Positive_Review']\\n#create the label\\nreviews_df['review_type'] = reviews_df['Reviewer_Score'].apply(lambda x: 'Bad_review' if x < 5 else 'Good_review')\\n#sample data in order to speed up the computation\\nreviews_df = reviews_df.sample(frac=0.1, replace=False, random_state=42)\\n#clean data\\nreviews_df['review'] = reviews_df['review'].apply(lambda x: x.replace('No Negative', '').replace('No Positive', '')) \""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We will perform several transformations to clean the textual data:\n",
    "- lower the text\n",
    "- tokenize the text and remove the punctuation\n",
    "- remove useless stop words\n",
    "- lemmatize the text\n",
    "\n",
    "In order to speed up the computation we will convert the csv data to pickle and continue working with the pkl file"
   ],
   "id": "17e1dee8bcb2a0d4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T09:54:36.573211Z",
     "start_time": "2024-06-18T09:54:36.561389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#lemmatize token and remove stop word, if len of word is greater than 1 remove it \n",
    "#convert the data to pickle\n",
    "'''\n",
    "from typing import List\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "def clean_text(text: str) -> List[str]:\n",
    "    doc = nlp(text)\n",
    "    return [token.lemma_ for token in doc if not token.is_stop and len(token) > 1]\n",
    "        \n",
    "#convert the csv data to pkl in order to speed up the computation  \n",
    "reviews_df['review_clean'] = reviews_df['review'].apply(lambda x: clean_text(x))\n",
    "reviews_df.to_pickle('dataset/Hotel_Reviews.pkl')\n",
    "'''\n"
   ],
   "id": "e95438ab9f1cffec",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom typing import List\\nimport spacy\\n\\nnlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\\n\\ndef clean_text(text: str) -> List[str]:\\n    doc = nlp(text)\\n    return [token.lemma_ for token in doc if not token.is_stop and len(token) > 1]\\n        \\n#convert the csv data to pkl in order to speed up the computation  \\nreviews_df['review_clean'] = reviews_df['review'].apply(lambda x: clean_text(x))\\nreviews_df.to_pickle('dataset/Hotel_Reviews.pkl')\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T08:59:49.628190Z",
     "start_time": "2024-06-16T08:59:47.843158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "\n",
    "with open('dataset/Hotel_Reviews.pkl', 'rb') as f:\n",
    "    reviews = pickle.load(f)\n"
   ],
   "id": "c365f475569b8047",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### tfidf Encoding\n",
    "\n",
    "We want to create document embeddings using bag-of-words approach "
   ],
   "id": "da15e40e1ad96ab5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:22:35.186560Z",
     "start_time": "2024-06-16T09:22:35.157568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import List\n",
    "from scipy.sparse import lil_matrix, csr_matrix\n",
    "import numpy as np\n",
    "\n",
    "class TfIdfModel:\n",
    "\n",
    "    #Create an index for the vocabulary from the docs\n",
    "    def build_index(self, docs: List[List[str]]) -> None:\n",
    "        self.index = dict()\n",
    "        words = [word for doc in docs for word in doc]\n",
    "        self.index = {word:i for i, word in enumerate(sorted(set(words)))}\n",
    "\n",
    "\n",
    "    def train(self, docs: List[List[str]]) -> None:\n",
    "        self.build_index(docs)\n",
    "        num_docs = len(docs)\n",
    "        num_terms = len(self.index)\n",
    "    \n",
    "        # Use a sparse matrix\n",
    "        term_doc_matrix = lil_matrix((num_docs, num_terms), dtype=np.float64)\n",
    "    \n",
    "        # Compute the term frequency matrix\n",
    "        for i, doc in enumerate(docs):\n",
    "            for term in doc:\n",
    "                term_doc_matrix[i, self.index[term]] += 1\n",
    "    \n",
    "        # Convert to CSR format for efficient arithmetic operations\n",
    "        term_doc_matrix = term_doc_matrix.tocsr()\n",
    "    \n",
    "        td_log_matrix = term_doc_matrix.copy()\n",
    "        td_log_matrix.data = np.log10(td_log_matrix.data + 1)\n",
    "    \n",
    "        df_vector = np.diff(term_doc_matrix.tocsc().indptr)\n",
    "        df_vector[df_vector == 0] = 1\n",
    "        idf_vector = np.log10(num_docs / df_vector)\n",
    "    \n",
    "        self.tfidf_matrix = td_log_matrix.multiply(idf_vector)\n",
    "\n",
    "\n",
    "    #Embed a word into our tfidf vector space If the word is not in the index it will return None\n",
    "    def embed(self, word: str) -> np.ndarray:\n",
    "        if word not in self.index:\n",
    "            return None\n",
    "\n",
    "        word_index = self.index[word]\n",
    "        word_vector = self.tfidf_matrix.getcol(word_index).toarray().flatten()\n",
    "        return word_vector\n",
    "\n",
    "    def vector_size(self) -> int:\n",
    "        return self.tfidf_matrix.shape[0]"
   ],
   "id": "d6456db9531b160e",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T10:07:57.641501Z",
     "start_time": "2024-06-16T10:07:57.628467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "#Create a document embedding using the bag of words approach\n",
    "def bagOfWords(model: TfIdfModel, doc: List[str]) -> np.ndarray:\n",
    "    embd_sum = np.zeros(model.vector_size())\n",
    "    valid_embeds = []\n",
    "\n",
    "    for token in doc:\n",
    "        embed = model.embed(token)\n",
    "        if embed is not None:\n",
    "            valid_embeds.append(embed)\n",
    "\n",
    "    if valid_embeds:\n",
    "        embd_sum = np.sum(valid_embeds, axis=0) / len(valid_embeds)\n",
    "\n",
    "    return embd_sum\n"
   ],
   "id": "af4afadea55326e",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-06-16T11:48:20.315936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = TfIdfModel()  \n",
    "docs = reviews['review_clean']\n",
    "model.train([review for review in reviews['review_clean'][:len(reviews)-1]])\n",
    "\n",
    "labels_train = np.array([])\n",
    "\n",
    "embed_train = np.array([bagOfWords(model,review) for review in reviews['review_clean'][:len(reviews)-1]])\n",
    "labels_train = np.array([review for review in reviews['Reviewer_Score']])\n",
    "\n",
    "print(embed_train.shape)\n",
    "print(labels_train.shape)"
   ],
   "id": "5dc8290dd8596957",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "51e82947e2aaad56"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
